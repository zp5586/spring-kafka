################## kafkaListener Producer 发送端 ##################
# brokers 集群
kafka.producer.bootstrap.servers = 192.168.43.242:9092,192.168.43.134:9092,192.168.43.228:9092

#发送端 id
kafka.producer.client.id = producerDemo

#发送端确认模式
kafka.producer.acks = -1

#发送失败重试次数
kafka.producer.retries = 3

#批处理条数,当多个记录被发送至统一分区时，producer对于同一个分区来说，会按照 batch.size 的大小进行统一收集，批量发送
kafka.producer.batch.size = 4096

#与 batch.size 配合使用。延迟统一收集，产生聚合，然后批量发送至broker
kafka.producer.linger.ms = 10

# 33554432 即32MB的批处理缓冲区
kafka.producer.buffer.memory = 40960

#默认 topic
kafka.producer.defaultTopic = testTopic

#key 序列化
kafka.producer.key.serializer = org.apache.kafka.common.serialization.StringSerializer

#value 序列化
kafka.producer.value.serializer = org.apache.kafka.common.serialization.StringSerializer


################## kafkaListener Consumer 消费端 ##################

#消费端 brokers 集群
kafka.consumer.bootstrap.servers = 192.168.43.242:9092,192.168.43.134:9092,192.168.43.228:9092

#消费者 group.id 组ID
kafka.consumer.group.id = test-group

#消费者消费消息后，进行自动提交
kafka.consumer.enable.auto.commit = true

#自动提交的频率(与 enable.auto.commit = true 属性配合使用)
kafka.consumer.auto.commit.interval.ms = 1000

#在使用kafka组管理时，发送心跳机制，用于检测消费者故障的超时
#kafka.consumer.session.timeout.ms = 1000

#key 反序列化
kafka.consumer.key.deserializer = org.apache.kafka.common.serialization.StringDeserializer

#value 反序列化
kafka.consumer.value.deserializer = org.apache.kafka.common.serialization.StringDeserializer

#消费端消费的topic
kafka.consumer.topic = testTopic
